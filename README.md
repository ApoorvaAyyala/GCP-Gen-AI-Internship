# GCP-Gen-AI-Internship
Google Cloud Generative AI

In this virtual internship, I've had 3 main modules.
The Modules include Beginner: Introduction to Generative AI Learning Path, Advanced: Generative AI for Developers Learning Path & lastly, Gemini for Google Cloud Learning Path

## Beginner: Introduction to Generative AI Learning Path
### 1. Introduction to Generative AI
I've learnt to:

• Define generative AI
• Explain how generative AI works
• Describe generative AI model types
• Describe generative AI applications.
### 2. Introduction to Large Language Models
I've learnt to:

• Define Large Language Models (LLMs)
• Describe LLM Use Cases
• Dxplain Prompt Tuning 
• Describe Google’s Gen AI Development tools
### 3. Introduction to Responsible AI
• Understood why Google has put AI principles in place
• Identified the need for a responsible AI practice within an organization 
• Recognized that decisions made at all stages of a project have an impact on responsible AI 
• Recognized that organizations can design AI to fit their own business needs and values
### 4. Prompt Design in Vertex AI: Challenge Lab
#### Challenge Scenario
You're a member of an educational content startup specializing in engaging learners with the natural world. You've formed a partnership with Cymbal Direct, an online retailer launching a new line of outdoor gear and apparel designed to encourage young people to explore and connect with nature.

Cymbal Direct wants to create a marketing campaign for its new product line that leverages the power of generative AI. Your task is to help them develop a set of tools within Google Cloud's Vertex AI platform that will streamline the generation of the following:

Evocative Product Descriptions: using image analysis to inspire short, descriptive text that captures the essence of their products and the feeling of being in nature.
Catchy Taglines: focused on highlighting product features, the target audience, and the desired emotional response.

Task 1. Built a Gemini image analysis tool

Task 2. Built a Gemini tagline generator

Task 3. Experimented with image analysis code

Task 4. Experimented with tagline generation code

#### Key Learnings from the above Lab:
⋆ Getting started with prompt engineering using the Google Gen AI SDK.

⋆ Applying best practices for prompt design, including conciseness, specificity, and task definition.

⋆ Explore various text generation use cases with the Google Gen AI SDK, such as:Ideation, Question answering, Text classification, Text extraction, Text summarization.

⋆ Created applications from prompts.

⋆ Design effective prompts.

⋆ Engineer and manage prompts.

⋆ Used multimodal prompts.

⋆ Installed the Gen AI SDK & Connected to an API service.

⋆ Sent text and multimodal prompts.

⋆ Learnt how to set system instructions.

⋆ Configured model parameters and safety filters.

⋆ Managed model interactions (multi-turn chat, content streaming, asynchronous requests).

⋆ Used advanced features (token counting, context caching, function calling, batch prediction, text embeddings).
### 5. Responsible AI: Applying AI Principles with Google Cloud
• Learnt about the impact of AI technology and Google's approach to responsible AI, and was also introduced to Google's AI Principles
• Learnt about how to make a business case for responsible AI, based on the report 'The Business Case for Ethics by Design' by the Economist Intelligence Unit
• Learnt about ethical dilemmas and how emerging technology such as generative AI can surface ethical concerns that need to be addressed
• Learnt about how Google’s AI Principles were developed and explore the ethical aims of each of these Principles
• Learnt about the practical application of responsible AI and how to operationalize AI principles by setting up and running reviews
• Learnt about the process of identifying possible ethical issues and identify issue spotting questions to think critically about the potential benefits and harms of a use case
• Learnt about the next steps and resources I can use to continue my responsible AI journey.
## Advanced: Generative AI for Developers Learning Path
### 1. Introduction to Image Generation
Had a sneak peek about diffusion models - the theory behind diffusion models and how to train and deploy them on Vertex AI. 
### 2. Attention Mechanism
Learnt how attention(a powerful technique that allows neural networks to focus on specific parts of an input sequence) works, how it can be used to improve the performance of a variety of machine learning tasks, including machine translation, text summarization and question answering.
### 3. Encoder-Decoder Architecture
Learnt about the stages in encoder-decoder architecture. Applied this technique to feed the source language sentence to the encoder and then compute the error between what the decoder generates and the actual translation.

[https://github.com/ApoorvaAyyala/GCP-Gen-AI-Internship/blob/main/Encoder-Decoder%20Architecture.ipynb](url)
### 4. Transformer Models and BERT Model
Learnt about the main components of the Transformer architecture, such as the self-attention mechanism, and how it is used to build the BERT model. I've also learnt about the different tasks that BERT can be used for, such as text classification, question answering, and natural language inference.

[https://github.com/ApoorvaAyyala/GCP-Gen-AI-Internship/blob/main/Transformer%20Models%20and%20BERT%20Model](url)
### 5. Create Image Captioning Models
Created an image captioning model by using deep learning. Also learned about the different components of an image captioning model, such as the encoder and decoder, and how to train and evaluate your model. Was also able to create your own image captioning models and use them to generate captions for images.
### 6. Introduction to Vertex AI Studio
I was introduced Vertex AI Studio, a tool to interact with generative AI models, prototype business ideas, and launch them into production. Through an immersive use case, engaging lessons, and a hands-on lab, I had the chance to explore the prompt-to-product lifecycle and learn how to leverage Vertex AI Studio for Gemini multimodal applications, prompt design, prompt engineering, and model tuning.
### 7. Vector Search and Embeddings
Explored AI-powered search technologies, tools, and applications in this course. Learnt semantic search utilizing vector embeddings, hybrid search combining semantic and keyword approaches, and retrieval-augmented generation (RAG) minimizing AI hallucinations as a grounded AI agent. Gained practical experience with Vertex AI Vector Search to build your intelligent search engine.
### 8. Inspect Rich Documents with Gemini Multimodality and Multimodal RAG: Challenge Lab
#### Challenge Scenario
You are a Marketing Campaign Coordinator at a media company, working closely with the Marketing Manager to plan, execute, and evaluate campaigns to meet sales targets. Recently, you secured an exciting new contract with Google. As a Marketing Campaign Coordinator, you’re eager to dive into the materials that will help you familiarize yourself with the Google brand and Google brand identity as quickly as possible. Therefore, you plan to review Google’s brand guidelines, previous campaigns, product ads, customer testimonials, and financial reports by leveraging Gemini’s innovative capabilities to gain deeper insights into Google more efficiently.

In this challenge, you begin with multimodal prompts to extract information from text and visual data, generating a video description, and retrieving extra information beyond the video by using multimodality with Gemini. You also build metadata of documents containing text and images, getting all relevant text chunks, and printing citations by using Multimodal Retrieval Augmented Generation (RAG) with Gemini.

Task 1. Generate multimodal insights with Gemini

Task 2. Retrieve and integrate knowledge with multimodal retrieval augmented generation (RAG)

[https://github.com/ApoorvaAyyala/GCP-Gen-AI-Internship/blob/main/inspect_rich_documents_w_gemini_multimodality_and_multimodal_rag-v1.0.0.ipynb](url)
#### Key Learnings from the above Lab:
⋆ Interacted with the Gemini API in Vertex AI.

⋆ Used the Gemini Flash model to analyze images and videos.

⋆ Provided Gemini with text, image, and video prompts to generate informative responses.

⋆ Explored practical applications of Gemini's multimodal capabilities.

⋆ Used the Gemini model (gemini-2.0-flash) to perform visual understanding

⋆ Took multimodality into consideration in prompting for the Gemini model

⋆ Created a retail recommendation application using the Gemini model

⋆ Extracted and store metadata of documents containing both text and images, and generate embeddings the documents

⋆ Searched the metadata with text queries to find similar text or images

⋆ Searched the metadata with image queries to find similar images

⋆ Using a text query as input, searched for contextual answers using both text and images
### 9. Responsible AI for Developers: Fairness & Bias
I've learnt to:

• Explored the toxicity text dataset
• Built and train a toxicity classification model
• Checked the model bias by plotting the prediction results
• Applied MinDiff technique using TensorFlow Model Remediation library
• Compared the result between the baseline and MinDiff models

[https://github.com/ApoorvaAyyala/GCP-Gen-AI-Internship/blob/main/Mitigate%20Bias%20with%20MinDiff%20in%20TensorFlow.ipynb](url)
#### Mitigate Bias with MinDiff in TensorFlow Lab's Key Takeaways:

Got to know Google's seven AI principles:
1. Be socially beneficial; 
2. Avoid creating or reinforcing unfair bias; 
3. Be built and tested for safety; 
4. Be accountable to people; 
5. Incorporate privacy design principles; 
6. Uphold high standards of scientific excellence; 
7. Be made available for uses that accord with these principles.

Learned about techniques that help mitigate bias - the refining data collection pipeline, balancing data, augmenting with other data, and relabeling data techniques all help mitigate bias in data and threshold calibration, MinDiff and counterfactual logic pairing help mitigate bias in models.
### 10. Responsible AI for Developers: Interpretability & Transparency
I've been introduced to:

• Interpretability and transparency in AI -  fourth of Google's AI principles
• Learned about interpretability techniques and how they are categorized into feature based, concept based, and example based methods
• Learned about feature based explanations where there are global techniques such as permutation, feature importance and partial dependence plots
• Learned about local methods such as LIME, Shapley values, Integrated gradients, and XR AI
• Also gained knowledge around concept based explanations such as TCAV, which aims to provide explanations
• Explored a few interpretability tools such as Open Source Library SHAP, Learning Interpretability Tool, and Vertex Explainable AI, as well as a few transparency tools such as data cards for data transparency and model cards for model transparency.

[https://github.com/ApoorvaAyyala/GCP-Gen-AI-Internship/blob/main/Responsible%20AI%20for%20Developers_Interpretability%20and%20Transparency.pdf](url)
#### Explaining an Image Classification Model with Vertex Explainable AI Lab's Key Takeaways:
Got a hands on experience on:
1. How to build and train a custom image classification model with Vertex AI;
2. Deployed the model to an endpoint;
3. Served predictions with explanations;
4. Visualized feature attributions from Integrated Gradients.

### Responsible AI for Developers: Privacy & Safety
This course introduced me to the important topics of AI privacy and safety.
#### Differential Privacy in Machine Learning with TensorFlow Privacy Lab's Keytakeaways:


1. Wrap existing optimizers into their differentially private counterparts using TensorFlow Privacy;
2. Practice checking hyperparameters introduced by differentially private machine learning;
3. Measure the privacy guarantee provided using analysis tools included in TensorFlow Privacy.
#### Safeguarding with Vertex AI Gemini API Lab's Keytaakeaways:


1. Call the Vertex AI Gemini API and inspect safety ratings of the responses
2. Define a threshold for filtering safety ratings according to your needs

### Machine Learning Operations (MLOps) for Generative AI
